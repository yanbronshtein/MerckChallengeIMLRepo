{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA of Heart Failure Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joel, Yaniv, Jeff<br>\n",
    "Merck Challenge - Project 2<br>\n",
    "Rutgers MSDS<br>\n",
    "2/4/21<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Items to Check for EDA:  \n",
    "1. Data loading and checking  \n",
    "2a. Numerical summaries  \n",
    "2b. Graphical summaries  \n",
    "3. Extract important variable(s) and analyze them  \n",
    "3a. Check for outliers and missing data  \n",
    "(Note: Did not include a on outliers (yet), as should determine the threshold of removing outliers first. I would suggest checking the jackknife residuals (refer to HW #6 from reg & TS))(EDIT: might be different for GLMs...)  \n",
    "3b. Develop and test simple models  \n",
    "3c. Test model assumptions\n",
    "\n",
    "Q: How much EDA should we do? (e.g. doing summaries of a few vs all variables, using some vs all of Yaniv's EDA code, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e000d66ecc2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Preliminaries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;31m# essential for data analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m \u001b[0;31m# gives tools for working with arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m \u001b[0;31m# useful for plots in general\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m \u001b[0;31m# needed for histograms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "### Preliminaries\n",
    "import pandas as pd # essential for data analysis\n",
    "import numpy as np # gives tools for working with arrays\n",
    "import matplotlib.pyplot as plt # useful for plots in general\n",
    "import seaborn as sns # needed for histograms\n",
    "import pylab as pyl #for generating plots: show()\n",
    "import statsmodels.api as sm  #to use the Logit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and Checking Data\n",
    "!pwd\n",
    "data = pd.read_csv(\"/Users/yanivbronshtein/Downloads/heart_failure_clinical_records_dataset.csv\")  # type and enter pwd and see if dataset is in same directory\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape # 299 rows, 13 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() # info about each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any() # check if any missing data\n",
    "# Q: Which variable(s) is dtype referring to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correlation matrix\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'DEATH_EVENT' # defining and checking descriptive stats of variable of interest\n",
    "series = data[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean: {}\".format(series.mean()))\n",
    "print(\"Stdev: {}\".format(series.std()))\n",
    "print(\"Min: {}\".format(series.min()))\n",
    "print(\"Max: {}\".format(series.max()))\n",
    "print(\"Median: {}\".format(series.median()))\n",
    "print(\"Mode: {}\".format(series.mode()))\n",
    "print(\"Skew: {}\".format(series.skew()))\n",
    "print(\"Kurtosis: {}\".format(series.kurtosis()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Graphical Summaries\n",
    "## Scatterplots\n",
    "sns.scatterplot(x = \"age\", y = \"DEATH_EVENT\", data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = \"diabetes\", y = \"DEATH_EVENT\", data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = \"sex\", y = \"DEATH_EVENT\", data = data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = \"age\", y = \"platelets\", data = data) # used for testing continous DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(data = data)\n",
    "# Q: How to zoom in on particular plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplots\n",
    "sns.boxplot(x='sex', y='DEATH_EVENT', data= data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='diabetes', y='DEATH_EVENT', data= data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='age', y='DEATH_EVENT', data= data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get variable names\n",
    "\n",
    "def getvar(x):\n",
    "    for i in x:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getvar(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Histograms\n",
    "# Note: See cell 22 in Yaniv's EDA notebook\n",
    "\n",
    "print(min(data['age']))\n",
    "print(max(data['age'])) # used to check if increasing or decreasing bins is needed\n",
    "data['age'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['anaemia']))\n",
    "print(max(data['anaemia'])) # used to check if increasing or decreasing bins is needed\n",
    "data['anaemia'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['creatinine_phosphokinase']))\n",
    "print(max(data['creatinine_phosphokinase'])) # used to check if increasing or decreasing bins is needed\n",
    "data['creatinine_phosphokinase'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['diabetes']))\n",
    "print(max(data['diabetes'])) # used to check if increasing or decreasing bins is needed\n",
    "data['diabetes'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['ejection_fraction']))\n",
    "print(max(data['ejection_fraction'])) # used to check if increasing or decreasing bins is needed\n",
    "data['ejection_fraction'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['high_blood_pressure']))\n",
    "print(max(data['high_blood_pressure'])) # used to check if increasing or decreasing bins is needed\n",
    "data['high_blood_pressure'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['platelets']))\n",
    "print(max(data['platelets'])) # used to check if increasing or decreasing bins is needed\n",
    "data['platelets'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['serum_creatinine']))\n",
    "print(max(data['serum_creatinine'])) # used to check if increasing or decreasing bins is needed\n",
    "data['serum_creatinine'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['serum_sodium']))\n",
    "print(max(data['serum_sodium'])) # used to check if increasing or decreasing bins is needed\n",
    "data['serum_sodium'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['sex']))\n",
    "print(max(data['sex'])) # used to check if increasing or decreasing bins is needed\n",
    "data['sex'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['smoking']))\n",
    "print(max(data['smoking'])) # used to check if increasing or decreasing bins is needed\n",
    "data['smoking'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['time']))\n",
    "print(max(data['time'])) # used to check if increasing or decreasing bins is needed\n",
    "data['time'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min(data['DEATH_EVENT']))\n",
    "print(max(data['DEATH_EVENT'])) # used to check if increasing or decreasing bins is needed\n",
    "data['DEATH_EVENT'].hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Outliers\n",
    "# Note: Can do it qualitatively or quantitatively... will be doing the former here. However, we can take the latter\n",
    "# approach if we so desired: https://medium.com/datadriveninvestor/finding-outliers-in-dataset-using-python-efc3fce6ce32\n",
    "# Q: Should use Judgement vs. IQR/Z-scores?\n",
    "\n",
    "# Ex # 1: platelets variable\n",
    "# Before\n",
    "sns.scatterplot(x='platelets', y = 'DEATH_EVENT', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After\n",
    "# See cell 32 in Yaniv's EDA notebook\n",
    "\n",
    "data = data[data['platelets'] <= 650000]\n",
    "sns.scatterplot(x='platelets', y = 'DEATH_EVENT', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex #2: age variable\n",
    "# Note: don't think we should exclude age, as study wanted to focus on all age groups, but just to see\n",
    "\n",
    "# Before\n",
    "sns.scatterplot(x='age', y = 'DEATH_EVENT', data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After\n",
    "\n",
    "data = data[data['age'] <= 85]\n",
    "sns.scatterplot(x='age', y = 'DEATH_EVENT', data=data)\n",
    "\n",
    "# Q: Which variables to ultimately include in predictive models? Important to know since they may need to be adjusted for outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "## NOTE: As DEATH_EVENT is a binary variable, we must do logit; linear regression will not work\n",
    "## Reference: https://gist.github.com/reenashaw/9de3608fa94f1a9ade0e19135afac70a\n",
    "\n",
    "data['int']=1 #explicitly create a placeholder for y-intercept: b0\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IV = ['age','sex','diabetes']\n",
    "model= sm.Logit(data['DEATH_EVENT'], data[IV])\n",
    "answer= model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer.summary() #summarize the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (K-Fold) Cross-Validation Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The following functions/commands are based on those from Yaniv's Logistic Regression Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before splitting data\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After splitting data and creating training data\n",
    "\n",
    "train_df = data.sample(int(data.shape[0] * 0.8))\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_rows = [idx for idx in data.index if idx not in train_df.index]\n",
    "len(testing_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating test data\n",
    "\n",
    "# test_df = data.iloc[testing_rows, :]\n",
    "# print(test_df.shape)\n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building logistic regression model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getvar(x):\n",
    "    for i in x:\n",
    "        print(i)\n",
    "\n",
    "print(getvar(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inlcude ALL numerical variables (thankfully, this data is clean...)\n",
    "\n",
    "train = train_df[['age','anaemia', 'creatinine_phosphokinase', 'diabetes', 'ejection_fraction', \n",
    "                  'high_blood_pressure', 'platelets', 'serum_creatinine', 'serum_sodium', \n",
    "                  'sex', 'smoking', 'time', 'DEATH_EVENT']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create x and y subsets of train and train data\n",
    "# note: DEATH_EVENT = response variable (y); dropped in training set?\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(train.drop('DEATH_EVENT', axis=1), \n",
    "                                                    train['DEATH_EVENT'], test_size = 0.20, \n",
    "                                                    random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train,Y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(Y_test, predictions))\n",
    "print(accuracy_score(Y_test, predictions)*100, \"%\")     # convert to %\n",
    "\n",
    "# Q: Should also produce smaller model (e.g. model with fewer variables), to see if this is improved model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Create the set`X` for the feature set and `Y` for the treatment variable from the dataframe** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['time','DEATH_EVENT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['DEATH_EVENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create function to perform the following:\n",
    "a)train, test, split the feature set and treatment set <br>\n",
    "b). Train a Random Forest Model with 100 trees and criterion entropy<br>\n",
    "c). Fit the Model<br>\n",
    "d). Generate the Predictions<br>\n",
    "e). Create the necessary metric reports**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random #Necessary so that the data is split according to a random metric\n",
    "import collections\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 101)\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, Y_train)\n",
    "random_forest_preds = random_forest.predict(X_test)\n",
    "print('The accuracy of the Random Forests model is :\\t',metrics.accuracy_score(random_forest_preds,Y_test))\n",
    "print(confusion_matrix(Y_test, random_forest_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing LIME modules\n",
    "\n",
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a function to display the patients that the model failed to classify correctly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_anomalies(model_preds):\n",
    "    index_list = []\n",
    "    for row_index, (input, prediction, label) in enumerate(zip (X_test, model_preds, Y_test)):\n",
    "      if prediction != label:\n",
    "        print('Row', row_index, 'has been classified as ', prediction, 'and should be ', label)\n",
    "        index_list.append(row_index)\n",
    "    \n",
    "    print(\"************************************************************************************\")\n",
    "\n",
    "    for index in index_list:\n",
    "        print(X_test.iloc[index,:])\n",
    "        print(\"************************************************************************************\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_anomalies(random_forest_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting x based on RFs (explained using lime)\n",
    "\n",
    "predict_fn_rf = lambda x: random_forest.predict_proba(x).astype(float)\n",
    "X = X_train.values\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X,feature_names = X_train.columns,class_names=['Died','Survived'],kernel_width=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Interpret LIME results (note: refer to data description for variable names and info)\n",
    "# Ex 1:\n",
    "\n",
    "print(X_test.loc[[38]],\"death event is: \",Y_test.loc[[38]])\n",
    "print(\"\")\n",
    "print(\"number of predictors are: \",len(X_test.columns))\n",
    "choosen_instance = X_test.loc[[38]].values[0]\n",
    "exp = explainer.explain_instance(choosen_instance, predict_fn_rf,num_features=12)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "\n",
    "## Frop top to bottom (right side of middle plot):\n",
    "## We can see that the follow-up period (days), level of serum creatinine in the blood (mg/dL), \n",
    "## percentage of blood leaving the heart at each contraction (percentage), and level of the CPK enzyme in the blood (mcg/L)\n",
    "## had the most positive influence on the patient's survivability. Considering these features and all others,\n",
    "## the patient had an 75% chance of surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.DataFrame(Y_test)\n",
    "df_b = pd.DataFrame(random_forest_preds)\n",
    "comparison = pd.DataFrame({\"Y_test\":Y_test, \"random_forest_preds\": random_forest_preds})\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 2:\n",
    "\n",
    "print(X_test.loc[[37]],\"death event is: \",Y_test.loc[[37]])\n",
    "print(\"\")\n",
    "print(\"number of predictors are: \",len(X_test.columns))\n",
    "choosen_instance = X_test.loc[[37]].values[0]\n",
    "exp = explainer.explain_instance(choosen_instance, predict_fn_rf,num_features=12)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "\n",
    "## Frop top to bottom (right side of middle plot):\n",
    "## We can see that the follow-up period (days) and the patient's age had the most positive influence \n",
    "## on the patient's survivability. Considering these features and all others, the patient had an 82% chance of surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ex 3:\n",
    "\n",
    "print(X_test.loc[[213]],\"death event is: \",Y_test.loc[[213]])\n",
    "print(\"\")\n",
    "print(\"number of predictors are: \",len(X_test.columns))\n",
    "choosen_instance = X_test.loc[[213]].values[0]\n",
    "exp = explainer.explain_instance(choosen_instance, predict_fn_rf,num_features=12)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "\n",
    "## Frop top to bottom (right side of middle plot):\n",
    "## We can see that the follow-up period (days), level of serum creatinine in the blood (mg/dL), \n",
    "## percentage of blood leaving the heart at each contraction (percentage), and level of serum sodium in the blood (mEq/L)\n",
    "## had the most positive influence on the patient's survivability.Considering these features and all others,\n",
    "## the patient had an 96% chance of surviving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ex 4:\n",
    "\n",
    "print(X_test.loc[[53]],\"death event is: \",Y_test.loc[[53]])\n",
    "print(\"\")\n",
    "print(\"number of predictors are: \",len(X_test.columns))\n",
    "choosen_instance = X_test.loc[[53]].values[0]\n",
    "exp = explainer.explain_instance(choosen_instance, predict_fn_rf,num_features=12)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "\n",
    "## Frop top to bottom (right side of middle plot):\n",
    "## We can see that the follow-up period (days), percentage of blood leaving the heart at each contraction (percentage),\n",
    "## and the patient's age had the most negative influence on the patient survivability. Considering these features and all others,\n",
    "## the patient had an 82% chance of dying."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takeaway:\n",
    "\n",
    "Based on some of the results above, it would seem that time is the most influential feature on the patient's survivability. This is expected, since, as patients age, they are more likely to experience heart failure, regardless of their gender. Whether they survive such a medical outbreak depends on their physiological makeup - particularly, certain chemical content in their blood, however.\n",
    "\n",
    "(Note: Would like to interpret more observations, but the code below doesn't work for certain values for some reason... tried 115, 44, 79, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Actually survived but model said they died\n",
    "print(X_test.loc[[155]],\"death event is: \",Y_test.loc[[155]])\n",
    "print(\"\")\n",
    "print(\"number of predictors are: \",len(X_test.columns))\n",
    "choosen_instance = X_test.loc[[155]].values[0]\n",
    "exp = explainer.explain_instance(choosen_instance, predict_fn_rf,num_features=12)\n",
    "exp.show_in_notebook(show_all=False)\n",
    "\n",
    "# Note: doesn't work for certain observations... how come? (code was already here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partial Dependence Plots (PDPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_test.columns.tolist()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pdpbox import pdp, get_dataset, info_plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdp_plot(model, feature_names, feature_name):\n",
    "    # Create the data that we will plot\n",
    "    pdp_goals = pdp.pdp_isolate(model=model, dataset=X_test, model_features=feature_names, feature=feature_name)\n",
    "\n",
    "    # plot it\n",
    "    pdp.pdp_plot(pdp_goals, feature_name)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_plot(random_forest, feature_names, feature_names[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_plot(random_forest, feature_names, feature_names[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_plot(random_forest, feature_names, feature_names[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_plot(random_forest, feature_names, feature_names[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_plot(random_forest, feature_names, feature_names[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2D PDP Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdp_2d(model, feature_names, indices, plot_type):\n",
    "    # Similar to previous PDP plot except we use pdp_interact instead of pdp_isolate and pdp_interact_plot instead of pdp_isolate_plot\n",
    "    features_to_plot = [feature_names[i] for i in indices]\n",
    "    inter1  =  pdp.pdp_interact(model=model, dataset=X_test, model_features=feature_names, features=features_to_plot)\n",
    "\n",
    "    pdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=features_to_plot, plot_type=plot_type)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (2,4), 'contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (2,7), 'contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (2,9), 'contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (4,7), 'contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (4,9), 'contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (7,9), 'contour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (2,4), 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (2,7), 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (2,9), 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (4,7), 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (4,9), 'grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pdp_2d(random_forest, feature_names, (7,9), 'grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapley Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
